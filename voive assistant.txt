import json
import queue
import sys
import sounddevice as sd
from vosk import Model, KaldiRecognizer
import pyttsx3

MODEL_PATH = "vosk-model-small-en-us-0.15"  # update to your folder

tts = pyttsx3.init()

def speak(text):
    print(f"Assistant: {text}")
    tts.say(text)
    tts.runAndWait()

def recognize_stream():
    q = queue.Queue()

    def callback(indata, frames, time, status):
        if status:
            print(status, file=sys.stderr)
        q.put(bytes(indata))

    model = Model(MODEL_PATH)
    rec = KaldiRecognizer(model, 16000)

    with sd.RawInputStream(samplerate=16000, blocksize=8000, dtype='int16',
                           channels=1, callback=callback):
        speak("Offline assistant ready. Speak now.")
        while True:
            data = q.get()
            if rec.AcceptWaveform(data):
                result = json.loads(rec.Result())
                text = result.get("text", "").lower()
                if text:
                    print(f"You: {text}")
                    handle_command(text)

def handle_command(cmd):
    if "time" in cmd:
        import time
        speak(f"The time is {time.strftime('%I:%M %p')}.")
    elif "hello" in cmd or "hi" in cmd:
        speak("Hello. How can I help?")
    elif "stop" in cmd or "exit" in cmd or "quit" in cmd:
        speak("Goodbye!")
        raise SystemExit
    else:
        speak("Try saying: what's the time?")

if __name__ == "__main__":
    recognize_stream()
